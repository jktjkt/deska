\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english,czech]{babel}
\usepackage{a4wide}
\author{Tomáš Hubík}
\title{Deska Scope Document}



\begin{document}

{\Huge \textbf{Deska}}

\vspace{0.2in}

{\large Tool for Central Administration of a Grid Site}

\vspace{0.5in}

{\large Scope Document}

\vspace{0.2in}

{\large Prepared for the Institute of Physics of the AS CR}

\vspace{0.2in}

{\large Version 1.3}

\vspace{0.2in}

{\large Date 2009-Nov-26}

\vspace{0.5in}

\subsection*{Revision History}

\begin{table}[!h]
	\begin{tabular}{l l l l}
		\textbf{Date} & \textbf{Version} & \textbf{Author} & \textbf{Description} \\
		2009-Oct-23 & V1.0 & Tomáš Hubík & Master plan \\
		2009-Oct-27 & V1.1 & Tomáš Hubík & Features specified \\
		2009-Nov-12 & V1.2 & Jan Kundrát & Changed the scope to aim at the
        Dashboard \\
		2009-Nov-26 & V1.3 & Jan Kundrát & Further clarifications for the
        motivation
	\end{tabular}
	\label{tab:RevisionHistory}
\end{table}


\subsection*{Document Review}

\begin{table}[!h]
	\begin{tabular}{l l l l}
		\textbf{Date} & \textbf{Version} & \textbf{Reviewer Name} & \textbf{Contact Info.} \\
	\end{tabular}
	\label{tab:DocumentReview}
\end{table}


\subsection*{Document Approval}

\begin{table}[!h]
	\begin{tabular}{l l l l}
		\textbf{Date} & \textbf{Version} & \textbf{Reviewer Name} & \textbf{Contact Info.} \\
	\end{tabular}
	\label{tab:DocumentApproval}
\end{table}


\newpage

\tableofcontents

\newpage

\section{Introduction}

\subsection{Purpose}
This document defines the project scope for the Tool for Central Administration of a Grid Site. It establishes the business need for 
the Deska, and it outlines the high level requirements needed to satisfy the specified need. This document is not an exhaustive 
requirements description, but will instead provide overall direction for a separate -- more detailed -- set of system requirements. 
This document's primary purpose is to establish priority among the most important issues, considerations, features, and overall goals.

\subsection{Scope}
The Deska will be responsible for managing and monitoring of a grid site. A
first goal is to automate configuration of several monitoring and deployment
tools, the second one is to provide a single web-based dashboard to look at the
status of the site from different perspectives and to integrate the output of
various monitoring tools, both in-house and remote, to a single place to check.


\section{Business Opportunity}

\subsection{Background}
One of the activities taking at the Institute of Physics of the AS CR (FZU) is running a local Tier-2 computing center connected to 
an international WLCG computing grid, running user programs from various scientific communities from the whole world. Currently 
installed capacity of the clusters is about 1500 CPUs with more than 250TB of disk storage. The center itself consists of several 
hundreds of physical machines. While certain policies and management tools were developed and deployed over the years, the center 
still lacks a centralized dashboard listing the state of various resources.\\
The administrators were pretty successful at deploying various industrial-standard management and monitoring tools. Nagios is used 
for fabric monitoring, most of the machine's configuration is being handled by Cfengine. SNMP agents are used for monitoring 
critical parts of the network infrastructure and Munin is used for generating graphs depicting performance characteristics of the 
computing nodes. Various in-house applications were developed to assist with keeping track of HW issues and interesting events.\\
Unfortunately, all these tools are currently being managed in an isolated manner. Despite some efforts, there is still no central 
place to define roles of machines which would in turn be used by all the other tools.

 
\subsection{Positioning}
The system will not replace any of the existing monitoring tools. It will replace only their web interfaces and display all the 
information by itself in a well-arranged way. It will substitute the unpractical way of configuration of currently used tools, 
that must be made manually by editing of several files now.

\subsection{Impact of Missed Opportunity}
The need for this system is motivated by several factors.  First of them is the duplication of information in current
implementation -- for example, the ``logical role'' of a system is currently defined on at least five places, and any change thus
needs to happen at all of them or inconsistencies show up.  Experience shows that any site which rolls out a similar
de-duplicating tool immediately improves their availability and reliability numbers.  Furthermore, certain tasks like deploying
new machines is made substantively easier by having just one place to perform any modifications.  Due to the nature of the
Institute, hard numbers are hard to estimate, but reducing deployment times by an {\bf order of magnitude} and at least {\bf
halving the maintenance windows} are not unheard of, and therefore build a rough estimate.

In an attempt to gather statistical data, the Institute's staff attempted to keep track of accidents and exceptional situations
encountered during a typical system maintenance.  It is important to note that many possible sources of trouble tend not to
manifest themselves too often, and therefore it is entirely expected that they did not contribute to this experiment at all.
Examples of such phenomenons are network issues which typically arise only when people are actually touching the equipment, like
when installing new computational resources.  No new machine installation took place and the staffers were not performing any
network maintenance at all.

One of the most critical problems encountered was the failure of 63 jobs belonging to the Atlas VO.  This interruption was
triggered by a scheduled reboot of a DPM disk pool node due to security reasons.  While both the managers and staffers of the
Institute recognize the importance of applying security patches, this particular situation could have been handled more
gracefully.  Had the administrator who was performing the kernel upgrade on the file server been aware of an ongoing activity
reaching the particular storage node, he might have decreased the number of allocated slots for production Atlas jobs, thus
limiting the number of failed jobs.  The staffers of the Institute are firmly convinced that a comprehensive dashboard, ideally
one matching the criteria specified in this text, would have mitigated the risk of failed production jobs.

Due to the nature of the grid site and the WLCG funding model, there are no financial loses associated with the unexpected
troubles.  The only damage which the site had suffered from was confined on the ``political'' and reputation level, as all
resource pledges were still fulfilled throughout the month.  Therefore, the management of the Institute refused to give any
estimate on possible financial risk associated with the missed opportunity, should the Deska system not be put in place.

Even more beneficial is the Dashboard, a system for aggregating monitoring and performance data from various places, both local
and from throughout the Grid.  The EGEE and WLCG projects have been successful in developing a number of monitoring tools, which
typically overlap in their scope for increased robustness.  However, the main problem of these tolls remains in their isolation.
As there are many places, many websites which publish their opinion about a site's availability and reliability, it is common for
system administrators to overlook certain minor indicators until the situation (and the provided service) deteriorates
significantly.  All of the staff at the Institute, both administrators and managers included, firmly believe that having a system
aggregating all the monitoring metrics will {\bf significantly reduce the latency between the discovery of a problem} by an
automated tool and {\bf the fix}.

Finally, another big reason is the effectiveness of the Unix system administrators.  Having a usable and convenient tools is
without any doubt a significant contributor towards increasing the employees' productivity.  Today's highly changing demands
combined with shortage of staffers' funding put high stress on the personnel, which might subsequently lead to the risk of
introducing subtle errors to the system.  Needless to say, de-duplication of data is crucial in order to prevent inconsistencies,
as keeping the same information at several places is tedious and error-prone.  Both the management and technical peronnel of the
Institute firmly believe that the Deska Database will therefore significantly mitigate the risk of systematic errors and thus
increase the site's availability and reliability.

Should the system not be put in place, it is expected that the grid site of the Institute will not cope with increased demands at
data processing, typically introduced by the scheduled start of the LHC accelerator and subsequent sudden increase in processed
jobs and managed data.

\section{Alternative solutions}
Most of the sites involved in the WLCG collaboration have either already developed, or are actively developing, a system, usually
database-based, for keeping track of the HW resources.  Such systems might involve just a pretty straightforward web application
with a bunch of forms providing an interface for the underlying data, or even a complex solution with well-defined API for
accessing the information stored therein.  However, no such project has been completed to a state where it is usable by more than
one grid site.  In fact, most of the systems involve a home-made, strictly locally-coupled approach, and their respective authors
have expressed their uncertainty about the future release of their products.  Therefore, no well-established products are
available for general consumption.

The FZU employees have conducted an evaluation of the possible solutions nonetheless.  Based on a feedback mostly obtained by
personal meetings, they have gathered information about three different solutions whose aim and scope might at least partially
overlap with the proposed Deska project.

\subsection{CC-IN2P3}
The scientists at the CC-IN2P3 institute in Lyon, France have developed an in-house project which is currently being refactored in
preparation to possible future release.  It is based on a MySQL setup, parts of the system communicate with the database directly
using a Perl library.  The system is tightly coupled with their instance of Puppet, a configuration and policy-based system
similar to FZU's cfengine.

While the sheer power of the tool is doubtlessly impressive, certain obstacles would have to be overcome if the decision was to go
with this particular project.  The main obstacle is the rather tight integration with the Puppet tool and subsequent design
choices.  While outside of scope of this document, certain properties of the database layout are likely not compatible with the
setup being deployed in Prague.  Another disadvantage is the lack of an enforced API (the database is still directly-available
after all) and the choice of the implementation language, as nobody in Prague wants to maintain yet another Perl-based tool.
Finally, system which has not been released (neither formally nor in an intermediate form suitable for testing) is not really a
sustainable tool.

\subsection{INFN}
The scientific collaboration in Italy (several cities) is currently attempting to heavily refit their Oracle-based system.  As
of late November 2009, no public release of the tool has been made, and the team has not been able to provide a detailed feature
list.  More details were not available at the time this document was written.

\subsection{Quattor}
Being developed in a collaboration of several sites, mostly from France, the Quattor tool is certainly an impressive piece of tool
originating in the HPC environment.  The following analysis is based on a quick narrative conducted by one FZU's employee which
might not be accurate, and therefore can not serve as a basis for thorough evaluation of the system.  However, the members of the
FZU's infrastructure team believe that it is close enough to the reality to suit well in this document.

Quattor tasks include a wide range of responsibilities, from problems like system installation and deployment to configuration of
the respective components.  Thus, the main issue with Quattor is related to this conception -- it might be implied that its
infrastructure encourages doing certain tasks in an independent and therefore non-standard way, hindering the process of migration
to an industrial-standard tool for central policy-based system administration like Cfengine or Puppet.  In contrast, the proposed
project goals of Deska put a heavy emphasis on re-use of existing, already deployed setups and well-known technologies.  The team
recognizes Quattor's strengths and conditions which lead to the design, but are lead to believe by experience that Quattor's
design choices would not fit nicely to the anticipated behavior of the Deska project.  Last but not least, reports say that
Quattor tends to impose unacceptably high latencies to each change being performed.

\section{Other non-HEP software}
Quite a lot of software pieces come from outside of the HPC/WLCG community, too.  After all, the LHC accelerator and the HEP
physics in overall is just one of the many most intensive users of grids and clouds.  Perhaps the most prominent piece of HW
inventory management is OCS Inventory.  However, its purpose is mainly targeted at people in charge of the physical hardware and
related housekeeping, and therefore does not fits the planned purpose of the Deska Database.

Another example of a tool which might seem similar at a quick glance is the Rack Monkey.  However, it supports only keeping track
of the physical location of the HW in the physical racks, and does not even support hardware in different cases than traditional
pizza-boxes like blade servers or other dense solutions.  Therefore, this system is not usable at FZU's environment which puts
emphasis on high space efficiency.

\section{Proposed Solution}

\subsection{Primary Functional Requirements}
In this section, we classify the primary features of the Tool for Central Administration of a Grid Site across three categories. 
Essential features cannot be done without. High-value features can be done without, although it may be very undesirable to do so. 
Follow-on Features are those for which it is not clear they should be included in the first release. In all cases, the lists are not 
exhaustive but include the most important features from a business perspective.

\subsubsection{Essential Features}
\begin{itemize}
	\item Central storage of authoritative information about the whole grid site
	\item Generating configuration files for various tools. For example Nagios, Cfengine
	\item Unified API for creating other modules
\end{itemize}

\subsubsection{High-Value Features}
\begin{itemize}
	\item Data aggregation from more tools to one well-arranged place, one place where to look for problems
\end{itemize}

\subsubsection{Follow-on Features}
\begin{itemize}
	\item Data correlation about load from various sources to determine if there is some dead lock, or hung application
	\item Implementation of modules for other tools, than those, that are currently used on FZU
\end{itemize}

\subsection{Primary Non-Functional Requirements (NFRs)}
In this section, we identify the primary non-functional requirements for the Tool for Central Administration of a Grid Site. This 
list is not exhaustive but is intended to capture the most important requirements from a business perspective. A full list of NFRs 
will be included in the SRS document.

\subsubsection{Performance, Throughput, and Scalability}
The system is expected to handle up to thousands of managed machines, tens of administrators with about ten changes performed each hour.\\
The system will provide a high level of scalability, so we will be able to run it over various monitoring and deployment tools. 
Configuring of single applications will be made by modules. These modules will use our system's API, so creating a new module for 
another application will be an easy task.

\subsubsection{Reliability and Availability}
Because of the fact, that our system will not replace any of the functional parts of current system, it is not necessary to be 
available 7 by 24 by 365.\\
It is necessary to be well protected against failure while generating configuration files, because this failure can lead to failure 
of the whole grid site. This will be made by some versioning of these files, so there will be some way back if this failure occurs.

\subsubsection{Security}
Several features of the system require authorization. The system will be divided into security levels. Each level will be allowed 
to make changes only of some attributes. Every module will have some list of attributes, which it will need, so if somebody 
does not have permission for changing all these required attributes, he will not be allowed to activate this module.

\subsubsection{Usability}
The application will be used by administrators who speak english, so the system will initially be translated into English.\\
It is also expected, that administrators have some experience with grid site maintenance.


\section{Risks}
Making some mistake in changing of attributes can have very serious consequence to the whole grid site. Therefore administrator can
check all generated configuration files and can make the final decision whether apply these changes, or not.


\section{Constraints}

\subsection{Development Process and Team Constraints}
At this time, there are no known constraints.

\subsection{Environmental and Technology Constraints}
At this time, there are no known constraints.

\subsection{Delivery and Deployment Constraints}
The application will be hosted on some machine with UNIX type operating system. The web part of the system will be browser 
independent.\\
FZU wants to have a possibility to influence the essential parts of design of the system, so we have to discuss all important issues
with administrators of FZU.

\end{document}
