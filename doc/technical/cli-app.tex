% vim: spelllang=en spell textwidth=120
\documentclass[deska]{subfiles}
\begin{document}

\chapter{The Console Application}
\label{sec:cli-app}

\begin{abstract}

In this chapter you can find the description of the {\tt Deska CLI}, the user interface for the whole system.

\end{abstract}

\section{Components}

The whole user interface is composed of five main components and two supporting ones.

When describing the architecture in direction from the DB, the first component is {\tt Deska::Cli::DbInteraction}. The 
whole CLI communicates with the DB through this class. The second part on our way to the user is {\tt Deska::Cli::UserInterface}.
Here you can find all definitions for single commands you can type to the command line, 
event loop handler and logics of communication with the user. This class is connected to another important component 
called simply, {\tt Parser}. All classes related to the CLI are placed in the namespace {\tt Deska::Cli}, so this one is not an 
exception and you can find it as class {\tt Deska::Cli::Parser}. This component is responsible for parsing of the 
command line. Each action, that user wans to perform writing it to the command line is represented by a signal emitted 
by this parser. All these signals are collected in a supporting component called {\tt SignalsHandler} and the {\tt Parser}
is then connected with the {\tt UserInterface} through this component. {\tt UserInterface} is also directly 
connected to the closest part of the application to the user, the {\tt UserInterfaceIO}. This class stands for a 
translator between questions and responses from the {\tt UserInterface} and the end user. Besides these five 
components, there is one more. The whole CLI needs some configuration values for its work. For obtaining these values 
is responsible {\tt Deska::Cli::CliConfig}.

Now we can describe all components in more detail.

\section{DbInteraction}

In the CLI part of Deska are used specific structures for manipulating data from the DB. We will describe firstly 
these structures, and then the role of {\tt DbInteraction}.

\subsection{Structures}

First structure is {\tt AttributeDefinition}. This one is very simple. It is containing attribute name ({\tt Db::Identifier}))
and its value ({\tt Db::Value}). {\tt AttributeDefinition} is not fully determined by itself as it 
does not contain any information about object to which this attribute with value belongs. So another structure is {\tt ObjectDefinition}.
This one is very similar to {\tt AttributeDefinition}, because it is also representing some kind of 
key - value structure. It contains kind name ({\tt Db::Identifier})) and object name ({\tt Db::Identifier})). The name 
is fully qualified, so in case of one object embedded using relations to another, this name will contain symbol "->" 
and both names. For example when we imagine kind "host" and embedded kind "interface". We can have one host -- "hpv2" 
and its "interface" -- "eth0". Now the {\tt ObjectDefinition} for this interface will have kind "interface" and name 
"hpv2->eth0". And now, when we have pair of {\tt AttributeDefinition} and {\tt ObjectDefinition}, we perfectly know, 
what value of which attribute belongs to a specific object. These structures are used for both assigning and obtaining 
the attributes from DB or creating objects. Another structure is a little bit more complicated. It is {\tt ContextStack}
and {\tt ContextStackItem}. {\tt ContextStack} is only a simple {\tt std::vector} of {\tt ContextStackItem} instances.
Under {\tt ContextStack} you can imagine some kind of path in directory structure on your computer where one item is not
a folder, but it is an object. When we use our example of {\tt ObjectDefinition}, the {\tt ContextStack} representing
the "interface eth0" will have two instances of {\tt ContextStackItem}: "host hpv2" and "interface eth0". You can see,
that in opposite to the {\tt ObjectDefinition}, {\tt ContextStackItem} is not fully qualified by itself. You must have
the whole {\tt ContextStack} in order to know which object is it representing. Till now we were talking about
{\tt ContextStack} representing only one object. In this case, {\tt ContextStack} contains only something like
instances of {\tt ObjectDefinition} without fully qualified names. {\tt ContextStackItem} could also represent a filter.
In this case it is a pair of kind name and {\tt Db::Filter}. Using context stack with a filter you can address a set of
objects with a specific characteristic. For example all interfaces of object "host hpv2" that belongs to a specific
network.

Because the work in the CLI is based mostly on the context stack as it is a natural way how to deal with the structure
of data in the DB and DBAPI is based on functions working with single objects or filters, we have the implemented the
class {\tt DbInteraction} to deal with conversion from context stack to format that is suitable for DBAPI.

\subsection{Context stack conversion}

As we described earlier, the context stack can be simple, without filters or more complicated with filters.

Conversion of {\tt ContextStack} to a single {\tt ObjectDefinition} is possible only when the {\tt ContextStack} does
not contain any filters. This type of conversion is very straight forward and could be done without queries to the DB.
We simply concatenate all object names from the stack with "->" symbol and use kind name from the last kind in the stack.

When we want to convert {\tt ContextStack} with filters, we have to perform queries to the DB. The conversion is made
step by step when going through the stack. In every time of the conversion we have a vector of all objects matching current
level of context stack. When the {\tt ContextStackItem} is representing an object, we only extend all names in the vector
with the "->" symbol and the object name from the {\tt ContextStackItem} and use kind name from the {\tt ContextStackItem}.
When the {\tt ContextStackItem} is representing a filter, we have to construct a large filter. Firstly we have to construct
a filter matching all objects in the vector. This is done by {\tt Db::OrFilter} containing all object names. Then we use
this filter together with filter from {\tt ContextStackItem} in a {\tt Db::AndFilter}. Now we have filter matching new
level of context stack, that can be used for performing operations through DBAPI.

\subsection{Caching}

Another role of class {\tt DbInteraction} is caching of several types of data to reduce network traffic, delays and
server load.

First caching is made on DB structure. {\tt DbInteraction} stores names of kinds and their attributes in several maps
(we used nested {\tt std::map} for implementation of these structures) for fast access to data needed for oparations with
the DB. Information like to which kind each attribute refers, in which kind is some kind embedded and more are stored
here.

Another chaching is performed on querries checking if some object exists or not, as these querries are quite frequent.
Because all queries to the DB are performed through this class, we can update our cache while performing modification to
the DB like creating objects, deleting objects, renaming objects and so on.

\section{UserInterface}

Class {\tt UserInterface} is the central class holding the logics of the CLI. This class serves like a glue connecting
all other components together.

It is driven by two types of commands. First type are commands implemented as classes inherited from {\tt Command}.

\begin{minted}{c++}
class Command
{
public:
    Command(UserInterface *userInterface);
    virtual ~Command();
    virtual bool operator()(const std::string &params) = 0;
protected:
    std::vector<std::string> complPatterns;
    std::string cmdName;
    std::string cmdUsage;
};
\end{minted}

As you can see, the base is very simple. In constructor several mandatory variables of the class are set like
completion patterns, command name, and usage description for help generation. These commands are infuencing the rest of
the Deska through pointer to {\tt UserInterface}. These command classes are stored in a map with their names as a key.
After that they are picked up using this name. Executing the command is made by calling function {\tt bool operator()} with
string as a parameter. This parameter could be then processed to influence behavior of each command. Return value is here
to tell the other world is the executing of the command succeeded or not. Names and parameters of these commands
are indepent on DB structure. Their purpose are things like operations with changesets, dumping, backuping and restoring
the DB and so on. We will describe each command separately in more detail later.

The second type of commands are dependent on DB structure. They are used for manipulating data in the DB like setting attributes,
creating, deleting and renaming objects and so on. Because of the fact, that these actions are performed using calls
like "<attribute-name> <attribute-value>" or "<kind-name>" "<object-name>", you can see, that here actualy is not any
name for this command. It is fully determined by the action it should perform. A special class was developped for parsing
of these "commands", class {\tt Parser}. It is one of the main components and also one of the most complicated, so we will
describe it later in a separate section. The parser itself does not change the datain the DB. It communicates with the
{\tt UserInterface} through simple class {\tt SignalsHandler}. This class is here because the parser emmits signals for
each action. These signals are caught and stored in the {\tt SignalsHandler}. Then comes two way processing of the stack,
where in the first round each action represented by one signal is confirmed and then when all signels are confirmed, they
are applyed to the DB. The confirmation and applying is performed via functions implemented in the {\tt UserInterface},
that you can see on the following snippet.

\begin{minted}{c++}
class UserInterface: public boost::noncopyable
{
public:

...

    bool applyCreateObject(const ContextStack &context,
            const Db::Identifier &kind, const Db::Identifier &object, ContextStackItem &newItem);
    bool applyCategoryEntered(const ContextStack &context,
            const Db::Identifier &kind, const Db::Identifier &object, ContextStackItem &newItem);
    bool applySetAttribute(const ContextStack &context, const Db::Identifier &kind,
            const Db::Identifier &attribute, const Db::Value &value);
    bool applySetAttributeInsert(const ContextStack &context, const Db::Identifier &kind,
            const Db::Identifier &attribute, const Db::Identifier &value);
    bool applySetAttributeRemove(const ContextStack &context, const Db::Identifier &kind,
            const Db::Identifier &attribute, const Db::Identifier &value);
    bool applyRemoveAttribute(const ContextStack &context, const Db::Identifier &kind,
            const Db::Identifier &attribute);
    bool applyObjectsFilter(const ContextStack &context, const Db::Identifier &kind,
            const boost::optional<Db::Filter> &filter);
    bool applyFunctionShow(const ContextStack &context);
    bool applyFunctionDelete(const ContextStack &context);
    bool applyFunctionRename(const ContextStack &context, const Db::Identifier &newName);

    bool confirmCreateObject(const ContextStack &context,
            const Db::Identifier &kind, const Db::Identifier &object);
    bool confirmCategoryEntered(const ContextStack &context,
            const Db::Identifier &kind, const Db::Identifier &object, bool &autoCreate);
    bool confirmSetAttribute(const ContextStack &context, const Db::Identifier &kind,
            const Db::Identifier &attribute, const Db::Value &value);
    bool confirmSetAttributeInsert(const ContextStack &context, const Db::Identifier &kind,
            const Db::Identifier &attribute, const Db::Identifier &value);
    bool confirmSetAttributeRemove(const ContextStack &context, const Db::Identifier &kind,
            const Db::Identifier &attribute, const Db::Identifier &value);
    bool confirmRemoveAttribute(const ContextStack &context, const Db::Identifier &kind,
            const Db::Identifier &attribute);
    bool confirmObjectsFilter(const ContextStack &context, const Db::Identifier &kind,
            const boost::optional<Db::Filter> &filter);
    bool confirmFunctionShow(const ContextStack &context);
    bool confirmFunctionDelete(const ContextStack &context);
    bool confirmFunctionRename(const ContextStack &context, const Db::Identifier &newName);

...

};
\end{minted}

Now we will describe how the more complicated commands from the first group work.

\subsection{Rebase}

Class {\tt Rebase} is quite complicated one. It's purpose is to reconnect current changeset from its parent to a new
one. This is done firstly by creating a new changeset, which will be connected to a newest revision and then by performing
the same changes as we performed in old changeset in this changeset. Then we can abort the old changeset. Well we can not
perform exactly the same changes in our new changeset, because the DB could change that it could not be possible. For
example when we set attribute of some object which was deleted in a newer revision. To solve this problem we are performing
some kind of merge here. We obtain two sets of {\tt Db::ObjectModificationResult}. Firs is diff between our old changeset
and its parent. This gives us list of our changes. Next set is diff between parent of our old changeset and parent of a
new changeset. This represents changeset made while we were working in our old changeset. These sets has to be somehow
merged and shown to a user in order to see, haw the final result of merge will look like and also in order to influence
the result of this merge. The merge is performed by several comparators and the result has to be in the following order:
\begin{enumerate}
    \item {\tt Db::DeleteObjectModification}
    \item {\tt Db::RenameObjectModification}
    \item {\tt Db::CreateObjectModification}
    \item {\tt Db::SetAttributeModification}
\end{enumerate}
This order was chosen because of constraints in the DB. For example when we are creating some object, the object with
the same name must not exist and so on. So deleting does not break any constraint any time. Rename is before create
because you can create then the object of the same name as an old one, but you will never need to perform create before
rename to unblock rename. Setting attributes must be last as it requires an existing object. After this sorting and
merging the result is shown to the user using an interactive editor implemented in {\tt UserInterfaceIO}. Here the user
can delete or modify the modifications. When the editting part is finished, the corrected list is processed and
all modifications are performed.

\subsection{Log}

Function {\tt bool Log::operator()} when executed without parameters only obtains list of all revisions in the DB and
prints this list using {\tt UserInterfaceIO} to the screen. The more interesting part of this class is parameters parser.
It is based on {\tt boost::spirit} as well as the {\tt Parser}. Parsing of parameters is done by class {\tt LogFilterParser}.
An output of this class is a {\tt Db::Filter}, that will be used directly for obtaining the list of revisions and similarily
printed using {\tt UserInterfaceIO} to the screen. Now we will describe the {\tt LogFilterParser}.

This class is inherited from {\tt boost::spirit::qi::grammar}. The grammar is based on three symbols tables with lazy lookup
function. This method could be found under name "Nabialek trick". We have to use this method as the grammer is build at
the runtime. This is because of the fact, thet we have to parse kind names, that are not known at compile time, but are obtained
from the DB. In the first symbols table there are names of metadata (author, timestamp, ...) and is filled at compile time
directly in the constructor. The second one is empty and will be filled using function {\tt void addKind(const Db::Identifier &kindName)}.
The third table contains operators. This parser is connected to three error handlers. {\tt LogAttributeErrorHandler}
for reporting an error while parsing an metadata name or a kind name, {\tt LogIdentifierErrorHandler} for reporting errors
while parsing of an object name and {\tt LogValueErrorHandler} for reporting an error while parsing a value of some
metadata. The {\tt boost::spirit} error handlers ale classes with function {\tt operator()}, that will be invoked every time
when the matching of the input to a specific rule fails. Each rule could have associated a number of error handlers. The
problem of this way how error handlers work is, that when some rule fails, error handlers of other rules cointaining this one
will be cascadely invoked. So we have to store all there errors in a stack and when some error occures process this stack
and inform user with a proper message. The whole grammar is build as a recursive expression parsing the input directly in the
recursive filers represented by {\tt Db::Filter}. You can see the logics on the following snippet:

\begin{minted}{c++}
start %= ((qi::lit("(") >> andFilter >> qi::lit(")"))
        | (qi::lit("(") >> orFilter >> qi::lit(")"))
        | (qi::lit("(") >> expr >> qi::lit(")")));

andFilter = (start % qi::lit("&"))[_val = phoenix::construct<Db::AndFilter>(_1)];
orFilter = (start % qi::lit("|"))[_val = phoenix::construct<Db::OrFilter>(_1)];

expr %= kindExpr | metadataExpr;

kindExpr %= (eps(!_a) > kindDispatch >> -eoi[_a = true]);
metadataExpr %= (eps(!_a) > metadataDispatch >> -eoi[_a = true]);

// Kind name recognized -> try to parse object name
kindDispatch = (raw[kinds[_a = _1]][rangeToString(_1, phoenix::ref(currentKindName))]
    > operators[_b = _1] > lazy(_a)[_val = phoenix::construct<Db::AttributeExpression>(
        _b, phoenix::ref(currentKindName), "name", phoenix::construct<Db::Value>(_1))]);
// Metadata name recognized -> try to parse metadata value
metadataDispatch = (raw[metadatas[_a = _1]][rangeToString(_1, phoenix::ref(currentMetadataName))]
    > operators[_b = _1] > lazy(_a)[_val = phoenix::construct<Db::MetadataExpression>(
        _b, phoenix::ref(currentMetadataName), _1)]);
        
phoenix::function<LogAttributeErrorHandler<Iterator> > attributeErrorHandler
    = LogAttributeErrorHandler<Iterator>();
phoenix::function<LogValueErrorHandler<Iterator> > valueErrorHandler
    = LogValueErrorHandler<Iterator>();
phoenix::function<LogIdentifierErrorHandler<Iterator> > identifierErrorHandler
    = LogIdentifierErrorHandler<Iterator>();
on_error<fail>(kindExpr, attributeErrorHandler(_1, _2, _3, _4,
    phoenix::ref(kinds), phoenix::ref(metadatas), m_parent));
on_error<fail>(metadataExpr, attributeErrorHandler(_1, _2, _3, _4,
    phoenix::ref(kinds), phoenix::ref(metadatas), m_parent));
on_error<fail>(kindDispatch, identifierErrorHandler(_1, _2, _3, _4,
    phoenix::ref(currentKindName), m_parent));
on_error<fail>(metadataDispatch, valueErrorHandler(_1, _2, _3, _4,
    phoenix::ref(currentMetadataName), m_parent));
\end{minted} 

When parsing some input using Nabialek trick, the rule, that is using the symbols table will not be entered when the keyword
is not found in the table. The {\tt eps} is there to ensure, that the {\tt kindExpr} and {\tt metadataExpr} rules will be
entered every time and so the error handler for bad keywords could be bound to it. The {\tt eoi} rule is there to avoid
the grammar require more input on the end of the line, which is side effect of eps usage in this way.

\subsection{Diff}

This function obtains list of {\tt Db::ObjectModificationResult} between two revisions or between changeset and its parent.
This depends on the parameters given. The output depends on the destination. If it is a diff to file the modifications
are sorted in the way like in {\tt Rebase}. This is because of the fact, that this output of the diff could be used for
example for backing the work in the changeset up. So we have to for example create the object bfore we are referencing it
in another object. This form of output is unfortunately not very user friendly. When the destination is a screen, the
modifications are sorted in the way, that modifcations of one objects are groupped. This allows us to better ilustrate
the obtained modifications.

\subsection{Dump}

Dump is performing some visual picture of the whole DB. The outpus is the same when dumping to the file or to the screen.
It is not intended to be used for backing anything up as it does not take any contraints in account.
The principle is very simple. We have a list of all kinds that could not be embedded in any other. This gives us a list
of "top-level" kinds. Now we can obtain instances of these kinds and for each instance we obtain list of embedded objects.
This is performed recursively. As the embedded objects can not live without their parents, we can print all objects in this way.

\subsection{Batch}

Class {\tt Batch} reads and performs cammands readable by the {\tt Parser} from a file. It could be used for reading of
an output from a diff.

\subsection{Backup}

Command "backup" is here to backup all persistent revisions from the DB including data. This is performed by obtaining
differences between each two revisons and saving these differences in a file. The order of the modifications is the same
as in case of diff to a file.

The format of the backup is following:

FIXME: Format this somehow

<list of modifications between r1 and r2, one per line>
...
@commit to r2
<author>
<commit message>
<commit timestamp>
#commit end
<list of modifications between r2 and r3, one per line>
...
@commit to r3
<author>
<commit message>
<commit timestamp>
#commit end
...

\subsection{Restore}

Restore reads backup created by {\tt Backup}. Restore is performed using function {\tt RevisionId restoringCommit(const
std::string &commitMessage, const std::string &author, const boost::posix_time::ptime &timestamp)}. The DB has to be
empty in order to perform restore. This is checket before any actions are made.

\subsection{Execute}

Command "execute" was implemented mainly for testing purposes. It reads commands from a file and performs actions. It
can read the same commands, that can be written to the CLI. The only difference is, that all command run in non-interactive
mode. This means, that user will not be asked for any confirmations as this would be impossible when reading commands from
a file.

\subsection{Help}



\subsection{Other commands}

There is a bunch of other comands, that are not very interesting. You can see a reference inline comments for more info.
Their names are {\tt Start}, {\tt Resume}, {\tt Commit}, {\tt Detach}, {\tt Abort}, {\tt Status}, {\tt NonInteractive},
{\tt Configdiff}, {\tt Exit}, {\tt Context}. 


\end{document}
