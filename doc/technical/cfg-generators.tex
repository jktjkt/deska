% vim: spelllang=en spell textwidth=120
\documentclass[deska]{subfiles}
\begin{document}

\chapter{The Configuration Generators}
\label{sec:config-generators}

\begin{abstract}
This chapter discusses the overall architecture of the configuration generators, components which turn the data in the
Deska database into a form directly usable by third-party applications.
\end{abstract}

\section{Basic Architecture}

The {\em configuration generators} are invoked by the Deska server whenever the output configuration has to be updated.
The generators communicate over a special pair of pipes (further described below in section \ref{sec:cfggen-pipes})
with the Deska server, reading contents of the Deska database over the already-discussed DBAPI protocol
(\secref{sec:dbapi-protocol}).  Most of the generators, and especially those shipped with the Deska as samples, are
implemented in Python, and therefore are built upon the high-level Python library (\secref{sec:python-bindings}) which
publishes the data from the Deska database as a tree of native Python objects.

The generators query the data in the database, perform target-specific transformation, and finally produce some output,
reflecting the new state of the database.  The generators are designed to run in a {\em stateless} manner, that is, a
generator shall always produce the same data when run repeatedly.\footnote{This is a slight oversimplification as some
generators {\em have} to maintain a global state between subsequent runs --- a typical example is the serial number of a
DNS zone file, which has to reflect both current date as well as the number of changes performed today, ensuring that
the serial number is always properly incremented.  This use case is further discussed in detail in the part about the
configuration generator setup as used in Prague in \secref{sec:fzu-cfggen}.}

The Deska server runs all configured generators in a sequence whose order is determined by their alphabetically sorted
names.  We have opted to use this triggering scheme for robustness.  The alternatives would be to let each generator
script express its dependencies in terms of data it is going to read, which would make the generators needlessly
complicated.  Deducing the data dependencies automatically is, unfortunately, equivalent to solving the halting problem
as the data generators are standalone {\em programs} capable of driving their execution in a completely independent way.

The output of the generators is processed by a shim layer of the {\em VCS/SCM integration} which provides the user with
an information about how the output as a whole has changed since the last time.  While nothing prevents development of
brand-new diffing tools and history management utilities, the Deska project ships with a tool which makes heavy use of
the Git~\cite{git} version control system, leveraging its content-tracking capabilities.  This integration is further
described in section \ref{sec:cfggen-scm-integration} later in this chapter.

The whole machinery is assisted by helper routines running in the scope of the PostgreSQL database.  These helpers make
sure that the configuration generators are run only when needed, maintain proper isolation between the parallel runs,
and handle the communication with the remote user.  Their operation is described in the least part of this chapter.

\subsection{Technical Requirements for the showConfigDiff DBAPI Method}

The DBAPI provides just a single method for running the configuration generators on the server side.  The aim of that
function is to handle everything ``behind the scenes'', from setting up the configuration output directory and
triggering the transformations to diffing the output.  The crucial idea here is that the CLI should not contain any
domain-specific knowledge of how the whole process works, but instead shall present the user with just a single ``show
me the changes'' functionality.

There are many methods for correctly transferring the diff information and conveying that to the user.  Current version
of the DBAPI spec deals with this complexity by essentially ignoring the complications and supporting only the most
rudimentary form of the changes, the {\tt git diff} output.

Using this approach, the actual data being transferred are simply dumped to the user's screen.  Everything else is
handled by the SCM integration layer of the Deska server.

\subsubsection{Pending Changesets}

The basic unit to operate on when dealing with the configuration generating scripts is a pending changeset.  Only a
changeset can possibly trigger output modifications, and only when transformed into a persistent revision.  Similarly,
the actual configuration data are needed either at the time of a commit (in order to be pushed into a SCM repository of
the output configuration files), or when the user wants to review them.  These two moments are identical for us --- they
identify a point in time where the output has to be ready and reflect the present state of the DB.

The output of the configuration generators is a function of the database state.  When the state of the database does not
change, neither should the configuration generators.\footnote{Again, the exception mentioned earlier about perfectly
valid use cases like the DNS zones are in fact supported.}  The Deska DB server can therefore cache the outputs on a changeset
level --- i.e. maintain a configuration output separately for each changeset.

\section{Database Access}
\label{sec:cfggen-pipes}

The configuration generators have to connect to a very precisely defined state of a database which is normally not
accessible to other connections (see section \ref{sec:cfggen-db-support} later in this chapter for further discussion
about this topic).  To achieve this goal in a robust and secure manner, the Deska server sets up an additional
out-of-band communication channel for this communication.  This side channel is implemented as a pair of unidirectional
{\tt pipe(2)} file descriptors.

During the course of normal operation, the Deska server simply reads the JSON data from its standard input, responding
to the received commands with JSON-encoded replies on the standard output.  When the generators are running, the server
will not process its standard input, but instead react to data which might arrive from the pipe set up for each
generator's needs.  We have settled on a pair of pipes, whose file descriptor number is passed through the environment
variables {\tt DESKA\_VIA\_FD\_R} and {\tt DESKA\_VIA\_FD\_W} mainly to achieve an easy integration with future scripts.
The {\tt libDeskaDb} library supports this communication method natively, and using a pair of pipes exposed through an
environment variable makes it easy to prototype the configuration generators even in other languages which do not have
proper bindings for this low-level library.  For example, communicating with the Deska database from a hypothetical
configuration generator implemented in Bash shell script is simply a matter of calling {\tt echo} and {\tt read} or {\tt
cat} with the appropriate output redirection.

The output from the configuration generators have to be redirected to a proper place as well -- the implementation could
not just use the Python's {\tt subprocess.PIPE} as the communication channel, because the code is using blocking reads
on the existing pipe pair, not paying attention to the child's {\tt stdout}, so there would be a real risk of filing up
the kernel-internal 4kB buffer dedicated to each pipe.  Redirecting the script output (both {\tt stdout} and {\tt
stderr}) to a securely-created temporary file proved to work well.

\section{VCS Integration}
\label{sec:cfggen-scm-integration}

One of the key requirements which the configuration generators have to fulfil is their ability to accurately track
differences between the previous, saved state and the newly generated output.  When combined with the fact that the
generated output is going to be saved in a VCS~\footnote{Version Control System} repository {\em anyway}, it is obvious
that delegating the change management to a fully fledged VCS will very likely lead to simpler, more efficient and robust
code, at least in the situations where the versioning backend supports efficient offline diffing.

As delivered, Deska ships with a backend which uses Git.  Being a distributed source code management system (SCM), Git
supports offline, local operations pretty effectively, and is therefore very efficient in the Deska use case as well.

The process starts with calling {\tt git pull} in the server-wide repository clone, hereby making sure that the status
on which we are going to operate is fresh enough and limiting the possible window for race conditions.\footnote{Git,
being a {\em distributed} system, does not guarantee that each modification already performed locally can be reproduced
in another copy at all times.  Instead, it relies on humans as the last resort when resolving conflicts.  Upon
collision, the Deska system will simply refuse to commit the result, and simply re-creating the output again, now based
on an updated initial state, will lead the eventual resolution.  As the whole operation does not depend on any local
state (even the DNS zones use just the database data and the repository state), this operation will never lose any
important information.}  When the repository is fresh, the {\tt git-new-workdir} is called to create a lightweight clone
of the original state of the produced output.  After this preparation, the configuration generators are run, overwriting
or augmenting the data in the checkout as they see fit.  When they finish their tasks, the Git integration scripts add
the new working directory contents to the git index and send the resulting staged diff to the remote user who initiated
the whole operation.  Should the generators run again at any time, a {\tt git reset} with the appropriate options
restores the checkout to its initial state, ready to accept an updated output.  Finally, when the changes are approved,
a {\tt git commit} along with {\tt git push} sends the data to the original, possibly remote Git repository.

Supporting various versions proved to be rather challenging.  Git offers a {\tt --porcelain} option for most of its
commands, but unfortunately the version of Git which ships on the Red Hat Enterprise Linux 5 is too old to support it
for the {\tt git status} command.  This is why the code falls back to calling {\tt git diff --cached --name-only} as a
slightly less efficient substitute.

\section{Database Support}
\label{sec:cfggen-db-support}

The Deska server, along with the database, has to keep track of the freshness of the generated configuration snapshot.
Any modification performed by the user on the contents of a database in a particular changeset has to void the cached
output copy.  This is implemented by a database stored procedure {\tt jsn.changesetHasFreshConfig}.

To prevent multiple sessions from running against the same changeset at the same time, possibly corrupting the
repository, the database enforces proper changeset locking through the
\deskaFuncRef{lockCurrentChangeset}/\deskaFuncRef{unlockCurrentChangeset} DBAPI methods.  A session has to have a
particular changeset {\em attached} before it is allowed to run the configuration generators, and a changeset which is
{\em locked} cannot be attached by any other session (which is, on the other hand, also one of the reasons why the
configuration generators have to jump through the extra hoops in order to get access to the database and why they use a
side channel instead of simply opening another connection).  The Deska server therefore locks the current changeset
before it starts running the configuration generators, effectively preventing any race conditions in the process.  This
procedure is extensively covered by the unit tests which try hard to simulate situations where a configuration generator
appears ``stuck'' and could be overtaken by a parallel session.

Finally, for performance reasons, it is extremely desirable for the configuration generators to look at the {\tt
production} tables, simply because accessing the once-prepared data is cheaper than retrieving them from the {\tt
history} tables all the time, incurring potentially very expensive function calls.\footnote{A real speedup on a machine
with fast SSD drive or a memory-backed database was more than thirty-fold.}  This is why the Deska server will at
first start a database transaction, then call the {\tt commitChangeset} SQL stored procedure to save the data into the
production tables, execute the configuration generators, and finally either commit the transaction (in case the
output refresh was triggered by a real, intended \deskaFuncRef{commitChangeset} DBAPI method), or execute a {\tt
ROLLBACK} in case the user did not want to actually commit the result just yet.\footnote{Incidentally, this workflow is
also the second reason for the out-of-band communication between the generators and the Deska database; the generators
have to use the same database session for their access.} Thanks to the database-level transactions, these operations are
guaranteed to not contain any race conditions.

\section{Examples}

With all the required theoretical background in place, we can now move on to concrete examples of how to use the Deska
database to produce useful output.  Let's start with a very basic configuration generator which merely produces a list
of hosts and the notes associated with them:

\begin{minted}{python}
#!/usr/bin/python
import deska
deska.init()

output = file("hosts", "wb")

for name, data in deska.host._all().iteritems():
    output.write("%s: %s\n" % (name, data.note))
\end{minted}

Placing the script above (for example as the \path{01-demo.py}) to the directory with the output generators (see section
\secref{sec:server-py} for the {\tt --cfggen-script-path} command line option and section
\secref{sec:build-cfg-generators} for the server setup) and making sure that the file is executable ({\tt chmod +x
01-demo.py}) is enough to test its functionality.

We will now discuss the script structure in detail.  The program starts with the necessary shebang line for the
operating system and initialization of the Python library (see section \secref{sec:python-bindings} for details on the
provided functions):

\begin{minted}{python}
#!/usr/bin/python
import deska
deska.init()
\end{minted}

The configuration generators should typically produce a certain output as their result.  The standard output of a script
is used only for debug purposes and is not stored anywhere.  The script shall therefore make sure that it explicitly
creates any files it needs:

\begin{minted}{python}
output = file("hosts", "wb")
\end{minted}

Any files produced below the script's working directory are going to be included in the final snapshot.  This directory
is shared among all of the configuration generating scripts, and will contain the old state of the configuration
snapshot before the first generator starts.

The final part of the script simply uses the familiar way of data querying (see section \secref{sec:python-bindings})
for fetching the data, which are then written to the target file:

\begin{minted}{python}
for name, data in deska.host._all().iteritems():
    output.write("%s: %s\n" % (name, data.note))
\end{minted}

\section{Tips and Best Practices}

The Deska database generally offers a reasonable performance, but there are certain steps which might improve the
performance without much complications.

First of all, every roundtrip to the database has an inherent cost.  The data which travel over the wire have to be
marshalled into their JSON serialization, but the simple act of going over the network socket might dominate the
execution time.

Suppose an application which has to produce an output for a DHCP server.  Doing that requires iterating over all hosts
(as we want to know the hostname), and for each of the hosts fetching a list of their network interfaces (which contains
crucial information like the VLAN, the IP address and the Ethernet MAC address).  If the database contains five hundred
hosts and each query takes only 9~milliseconds (which is, incidentally, a real-world number), fetching the whole set
consumes 4.5~seconds.  On the other hand, fetching a list of {\em all} interfaces in advance cut the {\em total}
execution time of the complete script to roughly 450~ms.  This approach is well illustrated in a real-world
configuration generator, the \path{scripts/config-generators/02-dhcp-dns} in the Deska sources (and on the attached CD).

Finally, letting one script produce configuration for related multiple unrelated services, as long as the source data
are similar, might reduce the time even more.  A good example is the \path{scripts/config-generators/05-services}, as
used in FZU, which uses the downloaded data of host roles to produce configuration for Nagios, Munin and Ganglia at
once.

\end{document}
