% vim: spelllang=en spell textwidth=120
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[czech,english]{babel}
\usepackage{a4wide}
\usepackage{listings}
\usepackage{longtable}
\usepackage{etoolbox}

\begin{document}

\title{Deska: The Database Access Protocol}

\author{Jan Kundr√°t}

\maketitle

\begin{abstract}
This chapter discusses design of the protocol that serves as an exclusive communication method for accessing the Deska
database server.  We discuss the overall design, as well as provide a detailed API reference along with example usage.
This document is intended to serve as a complete source of information for both DBAPI usage and possible independent
reimplementation.
\end{abstract}

\section{Background}

First of all, it might not be obvious why bother with designing a custom protocol for accessing a database.  The Deska
database, after all, is built on PostgreSQL which already provides a library which can be used to access database
servers.  However, using a RDBMS-specific transport library would make the Deska application suite needlessly tied to
one particular database server implementation.  Exposing a low-level SQL-like interface, even when wrapped by stored
procedures, would make it very hard to prevent users from accessing the database without first going through a
well-controlled set of entry points.  In addition to that, we argue that it is possible to provide an API which is
easier and safer to use, compared to the raw SQL usage.

\section{Protocol Overview}

The Deska Database API is modelled after a traditional RPC interface where user invokes a procedure on the remote host
and waits for its result.  This in turn determines the mode of operation, which happens in {\em command} -- {\em
response} cycles.  That is, after a client issues a particular command, it will block and wait for the server's
response.  No form of command pipelining is available at this point, but certain provisions are in place which will
allow future extensions towards non-blocking operation.

After defining the general mode of operation for an interface, there is a need to establish a method for serialization
of data sent over the wire.  There are many widely-used ways for serializing commands, from binary-only protocols to the
XML-RPC family.  For the Deska DB API, we have chosen to use JSON, a fairly recent arrival to the already broad family
of serialization standards.  The main reason behind this choice is the fact that the protocol itself is reasonably
terse, so that one can pretty easily look at the raw form of traffic and tell what is going on without using extra tools
or frameworks.  There is also quite a number of ready-made libraries for JSON parsing, so the JSON itself is as
ubiquitous as, say, the XML.

Even though the JSON standard itself is well-established, we still had to establish a common way of converting our RPC
requests to a particular JSON form. To that end, we have chosen to use JSON {\em objects}\footnote{The reader should get
herself familiar with the notion of JSON before continuing with the rest of this document, as we will not go into much
detail explaining how low-level JSON works.}, which are merely a sequence of key-value pairs, with key being a string
identifier and value an arbitrary JSON object.  

Due to certain technical limitations, a simple stream of JSON objects is rather impractical to parse.  In fact, none of
the common libraries for JSON parsing that we have tried play well with JSON streaming.  Some of these libraries would
happily attempt to blindly ``read everything'' from a stream, convert that to a string and only then attempt the actual
parsing.  Needless to say, such an approach will not work at all when the connection expects to exchange several rounds
of JSON command-response pairs, each of them occurring in response to the previous one.  Even the more advanced JSON
libraries have issues with parsing a sequence of JSON objects following each other, without any delimiters, as most of
these tools try to ``peek'' at the next character of the stream input after parsing a full JSON object, while the ``next
character'' is typically not available at that point.  Therefore, in order to facilitate the usage of these libraries,
we have chosen to mandate that each complete JSON object at the top-level scope has to be followed by a newline (LF),
the {\tt "\textbackslash n"} character.  Given that the newline character will never occur in a serialized JSON data,
this usage is completely safe and allows the protocol implementations to use per-line parsing for any IO interaction.

\section{JSON Serialization}

This section defines how an abstract notion of a command or response is converted to a JSON object.

\subsection{Commands and Responses}

Each command is uniquely identified by its name, and each command has a matching response with the same name. Therefore,
the hypothetical command {\tt foo}, which does not accept any arguments, will be transmitted in the following form (we
will omit the trailing line feed for brevity in the following examples):

\begin{lstlisting}
    {"command": "foo"}
\end{lstlisting}

A response is always constructed by simply changing the {\tt command} key to a {\tt response} literal, therefore a
response for the above command will look like this:

\begin{lstlisting}
    {"response": "foo"}
\end{lstlisting}

\subsubsection{Passing Arguments}

Most of the commands will very likely accept a few arguments.  These commands are transmitted in a very similar way to
the one we discussed above, with the arguments simply appended to the top-level JSON object.  All parameters are also
repeated in the relevant response:

\begin{lstlisting}
    {"command": "foo", "arg1": "arg1 value",
        "name of arg2": "some value"}
    {"response": "foo", "arg1": "arg1 value",
        "name of arg2": "some value"}
\end{lstlisting}

The JSON standard mandates that white space outside of string literals is ignored, and therefore implementations are
free to add it to make the JSON data more readable, or not include them at all.  In addition, to improve the
interoperability, the Deska DBAPI mandates that the order of appearance of individual key-value pairs inside a JSON
object is {\em not} significant, and therefore one is explicitly allowed to use a sequence of {\tt arg2}, {\tt command},
{\tt arg1} for the example above.  Please note that the order of key-value pairs in the response object can be different
than in the associated command.

\subsubsection{Returning Data}

So far we have only established procedures which do not return any usable data at all.  In practice, though, most of the
commands have to return a usable value.  This is achieved by extending the top-level JSON object of the response with a
single key named after the command, which contains the JSON serialization of the return value.  No other items are
added, changed or returned.

For example, if the above command was extended with a return value of {\tt string} type, a full command-response pair
would look like this one:

\begin{lstlisting}
    {"command": "foo", "arg1": "arg1 value",
        "name of arg2": "some value"}
    {"response": "foo", "arg1": "arg1 value",
        "name of arg2": "some value", "foo": "The returned value"}
\end{lstlisting}

Again, the order of appearance of the individual key-value pairs in a particular JSON object is not relevant.

\subsection{Serializing Data}

So far, we have mentioned that the data are transfered ``serialized as JSON values'', but did not specify how this
serialization is defined and what the mapping between native data types in a programming language (like an {\tt int}, or
a {\tt string}), the database server and the JSON transport is.  The following sections provide detailed information in
this matter.  For a quick reference, please check the overview tables in section \ref{sec:json-data-types-reference} on
page~\pageref{sec:json-data-types-reference}.

\subsubsection{Primitive types}

There are four basic data types in JSON, a {\tt string}, an {\tt integer}, a {\tt float} and a {\tt boolean}.  These
values are directly used for transport of the corresponding C++ data types.  However, this mapping is not fully
bidirectional for practical reasons -- one cannot look at the serialized JSON value and deduce what the original data
type was; a context is required for that operation.  This allows us to ``overload'' these JSON data types and serialize
multiple source types using a single JSON type.  A typical example of this is any particular C++'s {\tt enum}, whose
symbolic name is transmitted as a string literal with the matching name.

Suppose the following C++ definition:

\begin{lstlisting}[language=c++]
    enum Foo {
        BAR,
        BAZ
    };
\end{lstlisting}

A value of {\tt BAR} is transferred as a JSON string {\tt "BAR"}.  There is no technical way of distinguishing between
a value of the {\tt enum Foo(BAR)} and the string literal {\tt "BAR"}; the difference is always provided by the
context.

The JSON string is further overloaded for serialization of timestamps, ie. particular moments in time.  The C++ API uses
Boost's {\tt boost::posix\_time::ptime} as a timestamp representation, and serializes the data in the {\tt "YYYY-mm-dd
hh:mm:ss"} form, like {\tt "2011-04-07 17:22:33"}.

Similarly, a date is stored into the {\tt boost::gregorian::date} and serialized using the {\tt "YYYY-mm-dd"} form, like
{\tt "2011-04-07"}.

\subsubsection{Containers}

The Deska DBAPI supports passing two different kinds of containers, a {\em sequence} and a {\em map}.  The sequence is
usually represented by the C++'s {\tt std::vector}, while the map maps well to the {\tt std::map}.

A sequence is represented as the JSON's list with the individual list items being the respective serialization of the
underlying data type. Suppose we want to send a {\tt std::vector<int>} of (1, 2, 3) as the {\tt a1} argument of command
{\tt foo}:

\begin{lstlisting}
    {"command": "foo", "a1": [1, 2, 3]}
\end{lstlisting}

A map is only allowed to be indexed by string literals. A map similar to the sequence from the previous example would
look like this:

\begin{lstlisting}
    {"command": "foo", "a1": ["a": 1, "b": 2, "c": 3]}
\end{lstlisting}

The example above is equivalent to a {\tt std::map<std::string, int>} which contains $"a" \rightarrow 1$, $"b"
\rightarrow 2$ and $"c" \rightarrow 3$.  Please note that the order of appearance of these items in a map is undefined,
as the {\tt std::map} container will not respect the order of insertion.

\subsubsection{Custom Objects}

Custom objects, ie. instances of C++'s classes, are transmitted as JSON objects. Due to various popular JSON
impleemntations not respecting the order of appearance of individual values, the arguments to a class' constructor are
passed prefixed by name.  Therefore, given class {\tt Foo} with the following C++ constructor:

\begin{lstlisting}[language=c++]
    Foo::Foo(int i, const std::string &s);
\end{lstlisting}

We can modify our example command {\tt foo} to accept an instance of class {\tt Foo} like this:

\begin{lstlisting}
    {"command": "foo", "a1": {"i": 10, "s": "something"}}
\end{lstlisting}

Again, the user of the Deska DBAPI cannot infer the class name from this value without knowing an extra bit of
information about the syntax of the command {\tt foo} -- without that knowledge, we are typically not aware of the
existence of class {\tt Foo} at all.

Alternatively, certain simpler classes (like the IP addresses or MAC addresses of Ethernet interfaces) are better
transfered in their canonical string form.  As a rule of thumb, if a particular class has a rich internal structure, or
is complexity is closer to that of an {\tt Deska::Db::ObjectRelation} than to, for example, {\tt
boost::posix\_time::ptime}, it's better to use the complex form in preference to the string serialization.

It is also important to note that this section only serves as a generic guideline about how to proceed when implementing
JSON I/O for custom data types.  Considerable amount of work is required to be able to exchange custom values over JSON,
see section \ref{sec:json-extending} for details.

\subsubsection{Optional Values}

Certain data fields are designed to allow either a value of the underlying data type, or a special NULL value.  On the
C++ side, this is achieved by wrapping the data type inside a {\tt boost::optional<>} container.  In the JSON
serialization, the NULL can be simulated in two ways, either by omitting the value altogether, or by using JSON's {\tt
null} keyword as the JSON value.  The Deska DBAPI does not distinguish between the two conventions, so the following
examples are equivalent, provided that the arguments {\tt a1} is defined an accept NULL:

\begin{lstlisting}
    {"command": "foo", "a1": null}
    {"command": "foo"}
\end{lstlisting}

Please note that this rule does {\em not} translate to ``one can freely omit {\tt null} values in any place''; indeed,
explicitly returning {\tt null}s is compulsory e.g. when processing object attributes.

\subsection{Exceptions}

There are certain situations where the execution of a particular command terminates in an unexpected manner.  One reason
could be that the user of the API has made an error and for example tried to retrieve an object which does not exist, or
that the execution hit an implementation-specific failure which has to be communicated to the caller, like an error with
SQL processing.  For this reason and in order to prevent cluttering the API with artificial {\tt NULL} values and
special placeholders, the Deska DB API supports {\em exceptions}.

When the Deska server has encountered an error when processing a particular response, it will return a JSON object in
the usual form (ie. with {\tt "command"} replaced by {\tt "response"} and the rest of the data left intact), and instead
of adding the returned data in a key named after the API method, it will create another top-level key called {\tt
"dbException"} pointing to a JSON object representing an exception.  The new object will have the following structure:

\begin{lstlisting}
    {"type": "TypeOfException", "message": "description"}
\end{lstlisting}

Where the key {\tt "type"} is always a string identifying the exception and the {\tt "message"} always contains a string
with a textual message usable for debugging.  The object might contain more data, which could be used to pass
computer-readable data to the API user.  Usual rules for representing values apply here.

This is the list of currently defined exceptions, along with their other arguments:

\begin{longtable}{ p{44mm} p{80mm} p{24mm} }
    \caption{List of supported exceptions} \\
    Exception Name & Meaning & Additional arguments \\
    \hline
    \endhead
    {\tt NotFoundError} & The database does not contain such object & -- \\
    {\tt NoChangesetError} & Tried to perform an operation which requires being attached into a pending changeset
        without one & -- \\
    {\tt ChangesetAlreadyOpenError} & Tried to access/create/\ldots a changeset while being already attached to one & -- \\
    {\tt SqlError} & Execution of SQL statements resulted in an error & -- \\
    {\tt ServerError} & The server has experienced an internal error & -- \\
\end{longtable}

\subsection{Adding Low-Level Data Types}
\label{sec:json-extending}

Adding a low-level data type, ie. an equivalent of a {\tt string}, {\tt int} or similarly defined entity, is also
possible.  Users are strongly encouraged to contact the Deska project before undertaking these changes, if only to
prevent possible namespace clashes in future.

In general, the following has to be done to add a low-level data type to Deska:

\begin{itemize}
    \item Pick up an identifier to use
    \item Create the SQL data type, if applicable
    \item Create the corresponding C++ class, if applicable
    \item Extend the {\tt Deska::Db::Value} variant to include the new type
    \item Add further specializations of {\tt DeskaValueToJsonValue}'s {\tt operator()} for serializing the new type
        into JSON
    \item Create a specialization of the {\tt template<> struct JsonExtractionTraits<ObjectModification>} and its {\tt
        implementation()} method which is responsible for proper de-serialization of the JSON values
    \item Instantiate {\tt template JsonField\& JsonField::extract(T*);}
    \item Update the documentation and unit tests
\end{itemize}

\subsection{Serialization Quick Reference}
\label{sec:json-data-types-reference}

The following table provides a quick and compact overview of the officially supported data types and their respective
JSON serialization.  The first column, the name, is also used as the type identification in the {\tt kindAttributes()}
API function.

\begin{longtable}{ p{18mm} | p{35mm} p{41mm} p{45mm} }
    \caption{JSON serialization of data types for attribute values} \\
    Name & SQL Data Type & C++ Data Type & JSON Serialization \\
    \hline
    \endhead
    {\tt string} & VARCHAR & {\tt std::string} & {\tt "example text"} \\
    {\tt int} & INT & {\tt int} & {\tt 123} \\
    {\tt identifier} & VARCHAR & {\tt Deska::Db::Identifier} & {\tt "id-no-spaces"} \\
    {\tt double} & DOUBLE & {\tt double} & {\tt 333.666} \\
    {\tt date} & date & {\tt boost::gregorian::date} & {\tt "2011-04-20"} \\
    {\tt timestamp} & timestamp & {\tt boost::posix\_time::ptime} & {\tt "2011-04-20 14:28:33"} \\
    {\tt enum\_X}\footnote{See section \ref{sec:json-extending} for instructions about how to add new enumerations to both
        the Deska DB and the C++ library.} & ENUM (``A'', ``B'') & {\tt typedef enum \{A, B\} X} & {\tt "A"} \\
    {\tt X\_null}\footnote{The {\tt X} notion means that when there's an {\tt X} type defined and not postfixed by {\tt
        \_null} already, it is allowed to create a new data type by prefixing the original name with {\tt \_null}.} &
        \textless TYPE\textgreater~without the {\tt NOT~NULL} stanza & {\tt boost::optional<T>} &
        {\tt null} or the respective serialization for \textless TYPE\textgreater \\
\end{longtable}

In addition to the types mentioned above, which are usable and allowed as the data types for objects' attributes, there
are several ``internal'' data types which are exchanged over JSON, but which cannot be used in the context of
attributes.  These types are typically utilized for transfer of various data fields for internal purposes of the Deska
DBAPI JSON protocol, like type-safe serialization of revisions, changeset identification, passing along the object kind
relation information etc.  The following types are defined:

\begin{longtable}{ p{60mm} p{90mm} }
    \caption{JSON serialization of values for internal use} \\
    C++ Data Type & JSON Serialization \\
    \hline
    \endhead
    {\tt Deska::Db::RevisionId} & {\tt "r123"} \\
    {\tt Deska::Db::TemporaryChangesetId} & {\tt "tmp123"} \\
    {\tt std::vector<T>} & {\tt [A, B, C]}
        \newline(With the exact format of A/B/C depending on type~{\tt T})\\
    {\tt std::map<std::string, T>} & {\tt \{"key1": A, "key2": B, "key3": C\}}
        \newline(With the exact format of A/B/C depending on type~{\tt T})\\
    {\tt Deska::Db::PendingChangeset::\newline{~ ~}AttachStatus} &
        One of {\tt "DETACHED"} or {\tt "INPROGRESS"} \\
    {\tt Deska::Db::PendingChangeset} &
        {\tt \{"changeset": }TemporaryChangesetId{\tt, "author": }string{\tt, "status": }
        PendingChangeset::AttachStatus{\tt, "timestamp": }timestamp{\tt, "parentRevision": }RevisionId{\tt, "message": }
        string {\tt\}} \\
    {\tt Deska::Db::KindAttributeDataType} &
        One of {\tt "string"}, {\tt "int"}, {\tt "identifier"}, {\tt "double"}, {\tt "date"}, {\tt "timestamp"}, {\tt "enum\_X"} and
        {\tt "X\_null"} \\
    {\tt Deska::Db::ObjectRelation} &
        One of \newline {\tt\{"relation": "EMBED\_INTO", "target": }Identifier{\tt\}}, \newline
        {\tt\{"relation": "MERGE\_WITH", "target": }Identifier{\tt\}},
        \newline
        {\tt\{"relation": "IS\_TEMPLATE", "target": }Identifier{\tt\}} \newline or \newline
        {\tt\{"relation": "TEMPLATIZED", "target": }Identifier{\tt\}} \\
    {\tt Deska::Db::RevisionMetadata} &
        {\tt \{"revision": }RevisionId{\tt, "author": }Identifier{\tt, "timestamp": }timestamp{\tt,
        "commitMessage": }string{\tt\}}
        \\
    {\tt Deska::Db::ObjectModification} &
        One of \newline
        {\tt \{"command": "createObject", "kindName": }Identifier{\tt, "objectName": }Identifier{\tt \}}, \newline
        or \newline
        {\tt \{"command": "deleteObject", "kindName": }Identifier{\tt, "objectName": }Identifier{\tt \}}, \newline
        or \newline
        {\tt \{"command": "renameObject", "kindName": }Identifier{\tt, "oldObjectName": }Identifier{\tt,
        "newObjectName": }{\tt Identifier\}}, \newline
        or \newline
        {\tt \{"command": "setAttribute", "kindName": }Identifier{\tt, "objectName": }Identifier{\tt, "attributeName":
        }Identifier{\tt, "attributeData": }Value{\tt, "oldAttributeData": }Value{\tt \}} \\
    {\tt Deska::Db::ExpressionKind} &
        {\tt "columnEq"} or {\tt "columnNe"} or {\tt "columnGt"} or {\tt "columnGe"} or {\tt "columnLt"} or
        {\tt "columnLe"}
        \\
    {\tt Deska::Db::Expression} &
        One of \newline
        {\tt \{"condition": }ExpressionKind{\tt, "kind": }Identifier{\tt, "attribute": }Identifier{\tt, "value":
        }Value{\tt \}}, \newline
        or \newline
        {\tt \{"condition": }ExpressionKind{\tt, "metadata": }Identifier{\tt, "value": }Value{\tt \}}
        \\
    {\tt Deska::Db::Filter} &
        One of \newline
        {\tt \{"operator": "and", "operands": [}Expression, Expression,\ldots{\tt]\}}, \newline
        or \newline
        {\tt \{"operator": "or", "operands": [}Expression, Expression,\ldots{\tt]\}}, \newline
        or \newline
        Expression

\end{longtable}

\section{Database Interface}

The Deska DBAPI provides functions for accessing the information contained in the database.

\newcommand{\deskaFuncRef}[1]{{\tt {#1}}}

\subsection{The Deska DBAPI at a Glance}

The API can be divided into a few groups.  The first part are commands for querying the database scheme, which are
described in section \ref{sec:api-group-dbscheme}.  These commands inform you about what kinds of top-level objects are
defined, what relations exist among them and which attributes belong to each object.  Second part of the API
(section \ref{sec:api-group-data-retrieval}) is concerned with returning actual object data.  Going further, the third
part (section \ref{sec:api-group-data-modification}) focuses on manipulating the data in the database, while the fourth
part (section \ref{sec:api-group-vcs}) allows the user to manage the individual changesets and eventually commit the
results.  The last part (section \ref{sec:api-group-history}) discusses browsing the revision history.

Each session would typically start with a call to \deskaFuncRef{kindNames} to find out what kinds of top-level objects
are defined at all.  Applications which are interested in relations between objects, like what objects are designed to
``belong'' to other objects, and therefore are best represented as an embedded part, should call
\deskaFuncRef{kindRelations} to fetch that information.  Finally, calling \deskaFuncRef{kindAttributes} for each
top-level object will return attributes valid at the scope of each object.

After establishing the metadata structure, applications which require only read-only access can proceed with retrieving
individual objects' data.  The API provides a few functions for that, starting with the \deskaFuncRef{kindInstances} for
determining identifiers (names) of particular objects, \deskaFuncRef{objectData} for fetching values of object's
attributes, and \deskaFuncRef{resolvedObjectData} as a variant of \deskaFuncRef{objectData} which natively supports
resolving inherited values from object templates.

Before potentially using any methods for object modification, each application has to open a changeset to work in.  The
application can achieve that either by calling the \deskaFuncRef{startChangeset}, or possibly by attaching into one of
the already-created changesets (listed by \deskaFuncRef{pendingChangesets}) through \deskaFuncRef{resumeChangeset}.
Should the user decide not to need the pending changeset anymore, she can call the \deskaFuncRef{abortCurrentChangeset}
to permanently throw away any changes, or use \deskaFuncRef{detachFromCurrentChangeset} to ``detach'' from the
changeset, preserving the modifications for a later commit.  When all changes have been performed and the user decides to
make them permanent, she shall use the \deskaFuncRef{commitChangeset} to commit them into a persistent revision.

It is possible that someone has already committed a new version after our original user created a changeset, but before
she attempted a commit.  In that case, the new commit won't be performed, and the user should verify that the changes are still
valid via the diffing functions (see section \ref{sec:api-group-history}).  After the verification, the user shall use the
\deskaFuncRef{rebaseChangeset} to inform the database that the changeset is now based on a new, updated permanent
revision; this will allow a future \deskaFuncRef{commitChangeset} to succeed.

Objects can be created via the \deskaFuncRef{createObject} function, deleted through the \deskaFuncRef{deleteObject} and
renamed via the \deskaFuncRef{renameObject}.  Attribute values are set via the \deskaFuncRef{setAttribute} call.
Certain attributes accept a {\tt NULL} value, customary to model an unset attribute; to use it, also use
\deskaFuncRef{setAttribute}.  In case an object gets deleted by accident in a pending changeset, it can be restored to
its previous state via the \deskaFuncRef{restoreDeletedObject}.

Results of these modifying operations can be consulted via the \deskaFuncRef{listRevisions},
\deskaFuncRef{dataDifference} and \deskaFuncRef{dataDifferenceInTemporaryChangeset}.

\subsubsection{Revision Semantics}
\label{sec:api-revision-semantics}

Certain methods of the Deska DBAPI accept an optional argument for specifying a revision of the database data to which
the current query applies.  When the version is not specified, the implicit value is fixed at the latest persistent
revision which was committed at the time the session started.

When user attaches an existing pending changeset, this implicit value changes to the ``parent revision'' of the
current in-progress changeset.  Upon a successful commit, the implicit revision is set to the just committed revision.
Detaching from a pending changeset or aborting one sets the implicit revision number of the session to the latest
commit.

FIXME: atomicity

\subsubsection{Filtering Results}
\label{sec:api-filters}

Some functions defined in the DBAPI support reducing the working set of the data that they operate on via {\em filters}.
These functions are \deskaFuncRef{kindInstances}, \deskaFuncRef{dataDifference}, \deskaFuncRef{listRevisions} and
\deskaFuncRef{pendingChangesets}.  Each of them allows the user to specify a condition which, if present and not null,
will be applied to the domain of the data they operate on, and records which do not match the user-supplied filter will
be excluded from further evaluation.  This is intended to serve as an accelerator for operations which are best handled
with server-side searching.

A basic unit for building filters is a simple {\em expression}.  An expression compares value of an object's property
against a user-supplied constant using defined comparison operator.  At this time, the defined comparison operators are
equality, non-equality, being greater/lesser than, and greater-or-equal and less-or-equal.  The constant value against
which a property is compared can be anything which is acceptable in the context of a Deska attribute value, a revision
identification, or a temporary changeset identification.  The ``property name'' refers to the identifier of a property;
in case of regular objects stored in the Deska DB, these are the same as the attribute names.  In case of revisions, the
filter can query any property that is present in the objects included in the method's output, like revision IDs,
commit/changeset timestamps, revision authors, etc.

More complicated conditions can be created by chaining the operators into logical conjunction and disjunction.  At this
time, a filter can contain only one AND or one OR operator with a flat list of operands. No further nesting of these
operators is not allowed; this limitation might be lifted in future revision of the DBAPI specifications if the need
arises.

\subsection{API Reference}

\newcommand{\deskaFunc}[5]
{\paragraph{#1}\label{sec:api-ref-#1}

{#4}

{#5}

\subparagraph{Sample JSON input} {\tt \{"command": "{#1}"{#2}\}}

\subparagraph{Sample JSON output} {\tt \{"response": "{#1}"{#2}\ifstrequal{#3}{}{}{, "{#1}": {#3}}\}}

}

% usage: \deskaFunc{id}{comma and a list of arguments}{returned value}{summary}{detail}
\setcounter{secnumdepth}{4}

\subsubsection{Querying the Database Scheme}
\label{sec:api-group-dbscheme}

Functions in this group are used to query the scheme of the database, ie. a list of allowed objects, their attributes
and the defined object relations.

\deskaFunc{kindNames}{}{["z", "a", "b", "foo bar"]}
    {Return list of names of configured top-level Kinds.}
    {This function returns a list of configured top-level objects.  Any of these objects can be subsequently used in the
    {\tt kindName} argument to various other functions.}

\deskaFunc{kindAttributes}{, "kindName": "something"}
    {\{"bar": "int", "baz": "identifier", "foo": "string", "price": "double"\}}
    {Return a list of attributes defined for a particular kind identified by {\tt kindName}}
    {The returned data is a list of \textless name, datatype\textgreater { }pairs.}

\deskaFunc{kindRelations}{, "kindName": "something"}
    { [ \\
            \{"relation": "EMBED\_INTO", "target": "hardware"\}, \\
            \{"relation": "MERGE\_WITH", "target": "second-kind"\}, \\
            \{"relation": "IS\_TEMPLATE", "target": "target-kind"\}, \\
            \{"relation": "TEMPLATIZED", "target": "by-which-kind"\} \\
            ]}
    {Retrieve relations between different Kinds}
    {This function returns a list of relations for the specified kind of entities -- for more details and examples, see the ObjectRelation struct.}

\subsubsection{Retrieving Object Data}
\label{sec:api-group-data-retrieval}

Functions from this group are used for fetching actual data from the database.

\deskaFunc{kindInstances}{, "kindName": "something", "revision": "r123"}
    { ["a", "b", "c"] }
    {Returns identifiers of all objects of a given kind}
    {This function returns a list of identifiers describing all objects of a specified kind which are present in the
    database in the specified revision.  The {\tt revision} argument is optional, and if missing, its assumed value
    depends on the usual rules -- see section \ref{sec:api-revision-semantics} on page
    \pageref{sec:api-revision-semantics} for details.}

\deskaFunc{objectData}{, "kindName": "kind", "objectName": "object", "revision": "r123"}
    {\{"foo": "bar", "baz": "id", "int": 10, "real": 100.666, "price": 666\}}
    {Get all attributes for a particular object instance}
    {This function returns values of all attributes which are defined for the given object.  No template resolving is
    performed, see \deskaFuncRef{resolvedObjectData} for details.

    This function guarantees to return all attribute instances, including the {\tt null} values.  The only exception are
    embedded objects, for which the \deskaFuncRef{kindAttributes} returns a special attribute referring to the foreign
    key reference (in the demo setup, this would be the {\tt host} attribute for an {\tt interface}), but this special
    attribute is missing from the \deskaFuncRef{objectData} output.}

\deskaFunc{resolvedObjectData}{, "kindName": "kind", "objectName": "object", "revision": "r123"}
    {\\ \{"foo": ["obj-defining-this", "bar"], "baz": ["this-obj", 666]\}}
    {Get effective values for all attributes for a particular object instance, taking templates into account}
    {This function returns effective values of all attributes defined for a particular object or inherited from its
    template parent along with the identifier of the object at which level the value is specified.

    The amount of returned data is always the same as the \deskaFuncRef{objectData} result.}

FIXME: document output filters (\#210)

\subsubsection{Performing Modifications}
\label{sec:api-group-data-modification}

Any function which modifies objects stored in the Deska database belongs to this group.

\deskaFunc{deleteObject}{, "kindName": "something", "objectName": "name"}
    {}
    {Delete an instance of an object}
    {This function deletes a particular instance of an object of a given type from the database.}

\deskaFunc{createObject}{, "kindName": "something", "objectName": "name"}
    {}
    {Create a new instance of an object}
    {This function creates a new instance of a given object.  All attributes are initially unset, which means that you
    might have to call \deskaFuncRef{setAttribute} before you will be allowed to commit your changes if some attributes
    have a constraint not to be NULL.}

\deskaFunc{restoreDeletedObject}{, "kindName": "something", "objectName": "name"}
    {}
    {Undo an object deletion in the same pending changeset}
    {This function exists in order to enable ``undoing'' an object deletion in the same changeset where the deletion was
    attempted.  Due to the way how changesets are implemented, it is not allowed to delete an object and simultaneously
    create a new one with the same name in just one changeset.  Therefore, attempting to re-create a just deleted object
    as a remedy of the inadvertent action via \deskaFuncRef{createObject} will fail.  This function will instead
    completely undo the deletion, without leaving any trace in the history.  The object is completely restored,
    including all attributes and references.}

\deskaFunc{renameObject}{, "kindName": "something", "oldObjectName": "name", "newObjectName": "name"}
    {}
    {Change the name of an object}
    {This function will rename an object.  All references to the old name are automatically updated to point to the new
    one.}

\deskaFunc{setAttribute}{, "kindName": "something", "objectName": "name", "attributeName": "name", "attributeData": "something"}
    {}
    {Set an object's attribute to something}
    {This function will update the value of a particular object's attribute.  To remove an object's attribute, set its
    value to null.}

\deskaFunc{applyBatchedChanges}{"modifications": [ \\
    \{"command": "createObject", "kindName": "k1", "objectName": "o1"\}, \\
    \{"command": "deleteObject", "kindName": "k2", "objectName": "o2"\}, \\
    \{"command": "renameObject", "kindName": "k3", "oldObjectName": "ooooold", "newObjectName": "new"\}, \\
    \{"command": "setAttribute", "kindName": "k5", "objectName": "o5", "attributeName": "a5", \\
    "attributeData": "new", "oldAttributeData": "old"\} \\
    ]}
    {}
    {Apply a list of batched modifications at once}
    {Use this function to send a list of modifications to the database in one network operation, potentially saving
    substantial amounts of time.}

\subsubsection{Version Control}
\label{sec:api-group-vcs}

This group contains functions for creating, modifying and committing changesets.  For history, see the {\em Querying
History}, section \ref{sec:api-group-history}.

\deskaFunc{startChangeset}{}
    {"tmp123"}
    {Create a temporary changeset for modifying the DB}
    {This function will create a new changeset and immediately attach current session to it.  All changes performed in
    the session are stored in the temporary changeset.

    It is an error to attempt to create a new changeset while being attached to another one.
    }

\deskaFunc{commitChangeset}{"commitMessage": "message"}
    {"r123"}
    {Commit current in-progress changeset}
    {This operation will commit the temporary changeset (ie. everything since the corresponding
    \deskaFuncRef{startChangeset} call) into the production DB.  A new persistent revision will be created.}

\deskaFunc{rebaseChangeset}{"parentRevision": "r666"}
    {}
    {Make current in-progress changeset appear as a child of a specified revision}
    {In order to prevent a possible loss of information, Deska won't allow a commit of an in-progress changeset to the
    persistent, production revisions unless the latest persistent revision is the same as was present at the time the
    user started working on her in-progress copy. For example, if there was a revision X and user A started working on a
    changeset J, and while the J still was not comitted, another user went ahead and created revision X+1, user A won't
    be able to push her changes to the DB, as the J changeset is internally marked as "I'm based on revision X". In
    order to be able to push J and turn it into a persistent revision, it has to be explicitly marked as derived from
    X+1, which is exactly what this function performs.}

\deskaFunc{pendingChangesets}{}
    {[
     \{"changeset": "tmp123", "author": "user", "status": "DETACHED", "timestamp": "2011-04-07 17:22:33",
     "parentRevision": "r666", "message": "message", \\ "activeConnectionInfo": null\}
    ]}
    {Return a list of all pending changesets}
    {This function returns a vector of metadata for all pending changesets which are currently available in the
    database.  Without further arguments, this function will return information about changesets without any owner
    filtering.}

\deskaFunc{resumeChangeset}{"revision": "r123"}
    {}
    {Re-open a pre-existing changeset}
    {This function will attach current session to a pre-existing changeset which hasn't been committed yet. An example
    where doing that would be handy is upon the initial connect to the DB, where the client would typically call
    pendingRevisionsByMyself(), and ask the real person whether she wants to resume working on her changes, perhaps
    because the original session has died.}

\deskaFunc{detachFromCurrentChangeset}{"message": "clarify why"}
    {}
    {Detach this session from its active changeset}
    {This function will detach current session from its associated active changeset.  There could be many changesets in
    the Deska DB (all stored on the Deska DB server) which might belong to various users.  Each session (ie. a
    connection to the database) could only have at most one particular changeset associated with itself, and that
    changeset is called the {\em current} one.  It is the changeset that will receive all updates from the functions
    which perform database modifications.

    The purpose of this function is to facilitate a way to temporarily detach from a revision which still needs some
    time before it could be committed. After the former active changeset is detached, it remains available for further
    processing via the \deskaFuncRef{resumeChangeset} function, but the current session is not associated with an active
    changeset anymore. This is intended to make sure that user has to explicitly ask for her changes to be "set aside"
    instead of doing that implicitly from inside \deskaFuncRef{startChangeset}.}

\deskaFunc{abortCurrentChangeset}{}{}
    {Abort an in-progress changeset}
    {This function will throw away any changes made so far in the active changeset and remove that changeset from the
    list of pending changestes.}

\subsubsection{Querying History}
\label{sec:api-group-history}

Functions for browsing history of individual objects, retrieving lists of differences, etc.

\deskaFunc{listRevisions}{}
    {[
    \{"revision": "r123", "author": "user", "timestamp": "2011-04-07 17:22:33", "commitMessage": "message"\}
    ]}
    {Return a list of metadata for matching revisions}
    {This function returns a list of metadata for revisions matching the search criteria.  Given that there is currently
    no way to specify the search options (FIXME: add optional arguments?), the function will currently return metadata
    for all persistent revisions.}

\deskaFunc{dataDifference}{, "revisionA": "r1", "revisionB": "r2"}
    {[ \\
    \{"command": "createObject", "kindName": "k1", "objectName": "o1"\}, \\
    \{"command": "deleteObject", "kindName": "k2", "objectName": "o2"\}, \\
    \{"command": "renameObject", "kindName": "k3", "oldObjectName": "ooooold", "newObjectName": "new"\}, \\
    \{"command": "setAttribute", "kindName": "k4", "objectName": "o4", "attributeName": "a4", \\
        "attributeData": "new", "oldAttributeData": "old"\} \\
    ]}
    {Return differences between the database state in the specified versions}
    {This function will produce a list of differences between the database state in the two indicated revisions.  The
    returned value is a list of ``basic modifications'', each representing creation of a new object, deletion of an
    existing one, or setting a single attribute.  The order of the returned data is significant; for example, if an
    object has been created and its attribute set to a particular value, the creation shall be present before the record
    for setting an attribute.

    The format of the returned data is the same as the argument of \deskaFuncRef{applyBatchedChanges}.}

\deskaFunc{dataDifferenceInTemporaryChangeset}{, "changeset": "tmp123"}
    {[ \\
    \{"command": "createObject", "kindName": "k1", "objectName": "o1"\} \\
    ]}
    {Return differences between the database state in the specified versions}
    {See \deskaFuncRef{dataDifference} for details.}

\end{document}
